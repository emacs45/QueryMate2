import os

# W√§hle die Methode f√ºr Ollama: "requests" oder "library"
OLLAMA_METHOD = os.getenv("OLLAMA_METHOD", "library")  # Standard: "library"

# Konfiguriere die API-URL (nur f√ºr "requests"-Methode)
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://127.0.0.1:11434/api/generate")

# W√§hle den globalen Embedding-Typ: "huggingface" oder "nomic"
DEFAULT_EMBEDDING_TYPE = os.getenv("EMBEDDING_TYPE", "nomic")

# Nach dem √Ñndern neu initialisieren mit 
# python3 backend/chroma_index.py --reset

# W√§hle das Standard-LLM-Modell
DEFAULT_LLM_MODEL = os.getenv("OLLAMA_MODEL", "mistral:latest")

# Debugging-Ausgaben
#print(f"üîç Verwendete Methode f√ºr Ollama: {OLLAMA_METHOD}")
#print(f"üß† Verwendeter Embedding-Typ: {EMBEDDING_TYPE}")
#print(f"ü§ñ Standardmodell: {DEFAULT_LLM_MODEL}")
