# W√§hle die Methode f√ºr Ollama: "requests" oder "library"
OLLAMA_METHOD = "library"  # Standard: "library"

# Konfiguriere die API-URL (nur f√ºr "requests"-Methode)
OLLAMA_URL = "http://127.0.0.1:11434/api/generate"

# W√§hle den globalen Embedding-Typ: "sentence", "nomic", "mxbai" oder "bge"
DEFAULT_EMBEDDING_TYPE = "mxbai"

# Nach dem √Ñndern neu initialisieren mit 
# python3 backend/chroma_index.py --reset

# W√§hle das Standard-LLM-Modell
DEFAULT_LLM_MODEL = "mistral:latest"

# Debugging-Ausgaben
#print(f"üîç Verwendete Methode f√ºr Ollama: {OLLAMA_METHOD}")
#print(f"üß† Verwendeter Embedding-Typ: {EMBEDDING_TYPE}")
#print(f"ü§ñ Standardmodell: {DEFAULT_LLM_MODEL}")
