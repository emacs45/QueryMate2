# ğŸ¤– QueryMate2

**A local AI chatbot for company documents**  
> Developed as part of a practical bachelor thesis with a focus on privacy-friendly document retrieval using RAG (Retrieval-Augmented Generation).

---

<p align="center">
  <img src="output.gif" width="700"/>
</p>

## ğŸ” Features

- ğŸ“„ ** PDF Upload & Processing**  
  Extracts and splits content from uploaded PDFs

- ğŸ§  **Vector-based Knowledge Retrieval**  
  Document search using [ChromaDB](https://www.trychroma.com/)

- ğŸ”Œ **LLM Support (Local)**  
  Uses models from [Ollama](https://ollama.com/)  
  â†’ e.g. `mistral`, `llama3`, `gemma`, `nomic-embed-text`

- ğŸ§¬ **Embedding Backend Selection**  
  - HuggingFace (`sentence-transformers`)
  - Ollama (`nomic-embed-text`)

- ğŸ’¬ **User-Friendly Streamlit Interface**  
  - LLM model selection
  - Uploaded files list + delete option
  - Manual index refresh
  - Contextual Q&A interface

- ğŸ“¦ Privacy-First & Fully Local  
  - Runs entirely offline, no cloud dependency

---

## ğŸ§± Project Structure

```plaintext

QueryMate2/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ chroma_index.py         # Chroma index & vector search
â”‚   â”œâ”€â”€ ollama_client.py        # LLM requests via Ollama (API or library)
â”‚   â”œâ”€â”€ embedding.py            # Select and initialize embedding method
â”‚   â”œâ”€â”€ config.py               # Central configuration
â”‚   â””â”€â”€ logger.py               # Logging setup
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ ui.py                   # Main UI logic (Streamlit)
â”‚   â”œâ”€â”€ sidebar.py             # Model selector, index actions
â”‚   â””â”€â”€ faq.py                  # Help/FAQ sidebar section
â”œâ”€â”€ data/                       # Uploaded PDF documents
â”œâ”€â”€ models/chroma_index/       # Persistent vector index
â””â”€â”€ requirements.txt           # Python dependencies
              
```
---

## âš™ï¸ Installation

### Running the Application

1. Clone the Repository:

```sh
git clone https://github.com/emacs45/querymate2.git
cd querymate
```

2. Create a virtual environment

```sh
python3 -m venv venv
source venv/bin/activate
```

3. Install dependencies

```sh
pip install -r requirements.txt
```

---

### ğŸš€ Getting Started

#### Launch the Web UI:

```sh
streamlit run frontend/ui.py
```

#### (Optional) Reset and reindex PDFs:
```sh
python backend/chroma_index.py --reset
```

#### âš™ï¸ Configuration (via config.py or environment variables)

| Variable | Description | Default value |
| --- | --- | --- |
| `OLLAMA_METHOD` | Choose requests or library mode | *library*
| `OLLAMA_URL` | API URL if using requests method | *http://127.0.0.1:11434/api/generate*
| `EMBEDDING_TYPE` | Embedding backend: huggingface or nomic | *huggingface*
| `OLLAMA_MODEL` | Default LLM model | *mistral:latest*

### ğŸ§ª Sample Use Case

Q: â€œWhat changes are introduced in the latest software release?â€
QueryMate scans your internal documentation and provides a concise summary based on the extracted context.

### ğŸ“˜ License

MIT License â€” Free to use for learning, research, or internal company purposes.

---

### ğŸ‘¨â€ğŸ“ About the Project

This chatbot was developed as part of a Bachelor of Science in Business Informatics.
The goal was to prototype an AI assistant for SMEs that runs locally, protects sensitive data, and helps support agents or employees retrieve knowledge from internal documents quickly.

---

### ğŸ™Œ Contributions Welcome

Found a bug? Have an idea? PRs and Issues are welcome!